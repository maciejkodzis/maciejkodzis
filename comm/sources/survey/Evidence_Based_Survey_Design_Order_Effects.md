# Evidence-Based Survey Design: The Use of Ascending or Descending Order of Likert-Type Response Options

**Autorzy:** Ingrid Campbell  
**Rok:** 2018  
**Źródło:** Research & Theory Bucket  
**Język:** EN  
**Słowa kluczowe:** Likert scale, response order, survey design, bias, questionnaire layout

## 1. Streszczenie

EVIDENCE-BASED SURVEY DESIGN: THE USE
OF ASCENDING OR DESCENDING ORDER
OF LIKERT-TYPE RESPONSE OPTIONS
Seung Youn (Yonnie) Chyung, EdD Megan Kennedy Ingrid Campbell
Survey designers should be aware of response-order effects associated with left-side selection bias,
acquiescence bias, and satisﬁcing. A sufﬁcient amount of research has shown that descending-ordered
response scales generate more positive responses from respondents than ascending-ordered scales. A
simple solution to the inﬂated data obtained from descending-ordered scales is to present response
scales in ascending order. Otherwise, descending-ordered scales should be used with strategies for
reducing response-order effects.
INTRODUCTION
Survey questionnaires can be designed to be structured
orunstructured. Structured surveyquestionnairesconsist
of closed-ended questions, whereas unstructured survey
questionnaires use open-ended questions. A closed-
ended question provides preset response options such
as the Likert scale, and survey respondents are asked to
c h o o s eo n ef r o mt h eg i v e nr e s p o n s eo p t i o n s .C o n v e r s e l y ,
an open-ended question does not provide response op-
tions,andsurveyrespondentsanswerthequestionintheir
own words. Performance improvement practitioners and
researchers often use structured survey questionnaires in
their evaluations, needs assessments, and other perfor-
manceimprovementcontextstocollectquantitativedata.
To obtain valid and reliable data from survey ques-
tionnaires, the survey instruments must be designed to
minimizethenegativeeffectsofvariouspotentialresponse
biases.Thesurveyinstrument’svalidityandreliabilitycan
beinfluencedbythefollowingdesignfactors:
•Whethertousepositivelywordedsurveyitemsonlyor
amixofpositivelyandnegativelywordedsurveyitems
•Whether to use discrete rating scales such as Likert-
typescalesorcontinuousratingscaleswithsliders•WhethertouseamidpointornomidpointonLikert-
typescales
•Whether to use ascending or descending order when
listingresponseoptions
These seemingly simple decisions, however, require
a substantial amount of knowledge of survey design
and research-proven practices. When practitioners and
researchers design survey instruments based on their
ownpreferenceratherthanresearch-basedevidence,they
may get less than optimal data, often influenced by the
various factors listed in the preceding bullet points. A
vast amount of research has been conducted on these
topics, and teams of researchers from the Organizational
Performance and Workplace Learning department at
Boise State University have been reviewing research ar-
ticles to develop evidence-based recommendations for
developing structured survey questionnaires. The teams
of researchers have published a series of articles on the
following topics: the use of positively and negatively
worded statements (Chyung, Barkin, & Shamsy, 2018),
theuseofdiscreteandcontinuousratingscales(Chyung,
Swanson, Roberts, & Hankinson, 2018), and the use of a
midpoint in the Likert scale (Chyung, Roberts, Swanson,
&Hankinson,2017).
Performance Improvement, vol. 57, no. 9, October 2018
©2018 International Society for Performance Improvement
Published online in Wiley Online Library (wileyonlinelibrary.com) • DOI: 10.1002/pﬁ.21800 9
This article is another in a series of articles addressing
theissueofusingascendingordescendingorderofLikert
responseoptions.TheascendingorderofLikertresponse
options is Strongly disagree ,Disagree,Neutral,Agree,a n d
Strongly agree ,w h e r e a st h ed e s c e n d i n go r d e ri s Strongly
agree,Agree,Neutral,Disagree,a n dStrongly disagree .Th e
purpose ofthisarticleistwofold:(1)todescribe issuesto
beawareofwhenusingascendingordescendingorderof
Likert-type response options and (2) to present research-
based evidence and recommendations regarding the use
oftheorderofLikert-typeresponseoptionsinstructured
surveyinstruments.
RESPONSE BIASES ASSOCIATED WITH
RESPONSE-ORDER EFFECTS
Practitioners, as well as researchers, often need to make
data-drivendecisionsaspartoftheirevidence-basedprac-
tices. They collect data through various methods includ-
ing structured survey questionnaires and often become
survey designers. When designing and administering
structured survey questionnaires, it is important to un-
derstand the four steps that survey respondents exe-
cutewhileansweringeachindividualclosed-endedsurvey
item (Holbrook, Krosnick, Moore, & Tourangeau, 2007;
Tourangeau,1984):
1. Interpretingthequestion
2. Retrievinginformationfromtheirmemory
3. Integratingtheinformation
4. Selectingoneofthegivenresponseoptions
Under optimal conditions, survey respondents would
submittruthfulanswers.However,whensurveyitemsare
designedwithbiasorbecauserespondentscanhavesome
biased tendencies in responding to closed-ended survey
items, the collected data could be biased. To prevent re-
sponse biases, survey designers should be aware of psy-
chological phenomena associated with those biases. For
example, survey respondents may select different options
whentheresponseoptionsareorderedinascendingorde-
scendingorder—“theorderinwhichresponsealternatives
are presented to respondents may have a significant in-
fluence upon their selections” (Krosnick & Alwin, 1987,
p. 202). This phenomenon found in surveys is known as
response-ordereffects .
Two common types of response-order effects are pri-
macy and recency effects (Holbrook, 2008b). A primacy
effectrefers to the survey respondents’ tendency to se-
lecttheoptionsthatarepresentedatthebeginningofthe
response-option list. A recency effect is the opposite—the
tendency of survey respondents to select the options thattheyseeattheendoftheresponse-optionlist.Theprimacy
effectisexpectedwhenoptionsarepresentedvisually—for
example,peopletendtochooseamongthefirst-presented
categories in self-administered written survey question-
naires.Conversely,therecencyeffectisexpectedwhenop-
tions are presented orally (Holbrook et al., 2007). For ex-
ample,duringinterviews,peopletendtochoosefromthe
last-offeredoptions(Dillman&Christian,1995;Krosnick
&Alwin,1987;Schwarz&Oyserman,2001).Sincethisar-
ticleaddressesthedesignofwrittensurveyquestionnaires
to be self-administered, we will focus on the primacy
effect.
Applying theprimacy effect tothe survey respondents
whoareaccustomedtoreadingtextfromlefttoright,they
would likely select from the options that are presented
on the left. This phenomenon is described as left-side se-
lection bias .T h esatisficing theory also supports the pri-
macy effect. Simon’s (1957) satisficing principle explains
that “people usually seek solutions that are simply satis-
factory or acceptable in order to minimize psychological
costs” (as cited in Krosnick & Alwin, 1987, p. 203). Vari-
ousformsofsatisficingcanbeobservedinrespondentbe-
havior.Respondentsmayselectthefirstoptionthatseems
t ob er e a s o n a b l ee n o u g h ,c h o o s et oa g r e ew i t ht h eq u e s -
tion,select“Idon’tknow”insteadofreportingatrueopin-
ion, or randomly select one from the options provided
(Krosnick,1991).
Survey respondents are also known to show acquies-
cencebiasandsocial-desirabilitybias. Acquiescencebias is
thetendencyforrespondentstoagreewiththestatement
provided—aka yea-saying bias. One explanation for ac-
quiescencebiasisthesocialnormtobepolite(H olbrook,
2008a).Thisisexplainedas social-desirabilitybias ,theten-
dency for respondents to select among the options that
theythinkaremoresociallyacceptableordesirableinstead
oftheirtrueresponse(Callegaro,2008).Insurveys,select-
ingapositiveresponse(e.g., Stronglyagree orAgree)isper-
ceived to be more socially desirable. Therefore, after the
fourstepsthatsurveyrespondentsfollowwhenanswering
surveyquestions(interpret,retrieve,integrate,andselect),
theymayaddthefifthstep,“editingtheanswerforreasons
ofsocialdesirability”(Schwarz&Oyserman,2001).
The primacy effect, left-side selection bias, satisficing,
acquiescencebias,andsocial-desirabilitybiasarepsycho-
logical phenomena that survey respondents bring to the
table,whereasthesurveydesignisanenvironmentalfac-
torcontrolledbythedesigner.Theseresponsebiases,cou-
pled with the way the response options are presented
(in ascending or descending order), could influence the
overall survey results. When the response options are
presentedindescendingorder( Stronglyagree ,Agree,Neu-
tral,Disagree,Strongly disagree ), respondents would see
10www.ispi.org •DOI: 10.1002/pﬁ •OCTOBER 2018
a positive option immediately on the left side of the re-
sponse scale and perceive it to be socially desirable and
satisfactory,resultingintheirdecisiontoselectitwithout
h a v i n gt os p e n dm o r et i m et oc h o o s eat r u er e s p o n s e .
However, the same effects may or may not happen when
the response options are presented in ascending order
(Stronglydisagree ,Disagree,Neutral,Agree,Stronglyagree ).
Whathasresearchshownabouttheeffectsofusingas-
cendingordescendingorderofresponseoptionsinstruc-
turedsurveyquestionnaires?Whatstrategiescanbeused
to minimize the response-order effects? In the following
section, we will discuss evidence from the past several
decadesofresearch.
RESEARCH FINDINGS ON THE USE OF
ASCENDING OR DESCENDING ORDER
Many Studies Show Left-Side Selection Bias
from Ascending-Order Scales Generating
Higher Mean Scores.
One of the early investigations on response-order effects
was Belson’s (1966) study. In his study, two groups of re-
spondentsinLondonfrom16to70yearsofagecompleted
a36-itemquestionnaireinatest-roomcondition.Agroup
of167usedaverbalratingscaleindescendingorder(i.e.,
positiveitemsfirst)andanothergroupof165participants
used a verbal rating scale in ascending order (i.e., nega-
tive items first). Belson found that whichever end (posi-
tiveornegative)wasprovidedfirstwasmorepronetoor-
dereffects.Ifthepositiveoptionwaspresentedfirstonthe
left side, respondents were more likely to select it, and if
the negative option was presented first, the respondents
were also more likely to select it. This indicated a left-
side selection bias, or primacy effect, in response-order
selection.
Friedman, Herskovitz, and Pollock (1993) also found
left-side selection bias from their study with 208 col-
lege students in the United States. The researchers asked
students to rate their attitudes towards college on a 10-
item survey with a 5-point Likert scale presented in ei-
therascendingordescendingresponseorder.UnlikeBel-
son’s findings, the left-side selection bias was found only
when response options were presented in descending or-
der (Strongly agree on the far-left side). As a result, stu-
dents’ ratings from the descending-ordered scale were
higherthanthosefromtheascending-orderedscale.This
indicates that acquiescence bias may have been in effect;
however, this bias was present only for positively worded
survey items. For negatively worded items, the response
order did not affect the respondents’ selection. This shift
towards positive responses is likely a result of satisficingleadingtoaprimacyeffectandleft-sidebias,selectingthe
satisfactory option presented first when it was presented
ontheleftsideratherthanontherightsideofthescale.
Similarly, Chan (1991) studied the response-order ef-
fectwith102seniorhighschoolstudentsinTaipei.These
students completed a five-item personal distress scale
translatedintoMandarinwithdescendingresponse-order
options (e.g., “ d e s c r i b e sm ev e ryw e l l ,” “describes me quite
well,” “describes me well ,” “describes me slightly well ,” and
“does not describe me well ”). Five weeks later, they took
t h es a m es u r v e yb u tw i t ht h er e s p o n s eo p t i o n ss w i t c h e d
to ascending order. The results of this study also showed
asignificantlyhighermeanfromthedescending-ordered
scale.Theresearcherinterpretedthistomeanthatthestu-
dentswereinfluencedbytheprimacyeffectandchosepos-
i t i v eo p t i o n sm o r eo f t e nw h e nt h e yw e r ep r e s e n t e dfi r s t .
Based on these findings, the researcher advised against
using both ascending- and descending-ordered scales in
the same survey. He also advised against the practice of
reverse-codingdatafromnegativelywordeditemsbecause
thereverse-codedscoreswouldvaryfromtherawscore.
However, Barnette (2000) discussed a benefit of using
b i d i r e c t i o n a lr e s p o n s eo p t i o n s .H et e s t e ds i xs t u d yc o n -
ditions in a 2 ×3 framework: (1) the survey items were
all positively worded or mixed with positively and nega-
tivelywordeditemsand(2)Likert-scaleresponseoptions
were ascending, descending, or mixed with both. A total
of915adultsintheUnitedStateswereassignedtooneof
the six conditions and asked to complete a 20-item sur-
vey.Thehighestreliabilitywasfoundinthesurveydesign
thathadonlypositivelywordeditemsandbidirectionalre-
sponse options (half with ascending order and the other
halfwithdescendingorder).Theresearcherproposedthat
thisdesignoptionwouldhelpguardagainstacquiescence
orresponse-setbias.
Compared with the use of bidirectional response
options, Nicholls, Orr, Okubo, and Loftus (2006) recom-
mended a similar yet different approach based on their
study with 292 college students in Australia. Participants
completed a 22-item survey with a 5-point Likert scale;
half of them received the survey with responses in as-
cendingorder(from Definitelydisagree toDefinitelyagree )
and the other half in descending order (from Definitely
agreetoDefinitely disagree ). The results of this study
again demonstrated higher scores from the group that
completed the survey with a descending-ordered scale.
The researchers cautioned about the left-side selection
bias,especiallywhensurveyinstrumentsareusedtomake
absolutejudgments(e.g.,itissatisfactoryifthemeanscore
isaboveacertainscore),asopposedtorelativejudgments
(e.g., how Group A’s satisfaction scores compared with
Group B’s satisfaction scores). To control the left-side
Performance Improvement •Volume 57 •Number 9 •DOI: 10.1002/pﬁ 11
selection bias effectively, the researchers recommended a
m e t h o dw h e r eh a l fo ft h er e s p o n d e n t sc o m p l e t eas u rv e y
with an ascending-ordered scale and the other half use a
descending-orderedscale.
A st h ew e bb e c a m eap o p u l a rs u r v e yt o o l ,r e s e a r c h e r s
studied response-order effects in web-based surveys. For
example, Hartley and Betts (2010) asked 465 academic
writers,reviewers,andinformationscientiststorateanab-
stract using an 11-point scale. Each participant was ran-
domlyassignedtooneoffourconditionscreatedbyusing
different directions of worded labels ( CleartoUnclear,o r
UncleartoClear) and different directions of numeric rat-
ings(10to0,or0to10),asshownhere:
1. Clear109876543210U nclear
2. Clear012345678910U nclear
3. U nclear109876543210Clear
4. U nclear012345678910Clear
Theresearchersfoundthatthefirsttype,thescalestart-
ingwithapositivelywordedlabel( Clear)andahighestnu-
mericalvalue(10),resultedinsignificantlyhigherratings
ascomparedwiththeotherthreeresponseoptions.
To expand their understanding of this topic, Betts and
Hartley(2012)administeredapaper-basedsurveytochil-
dren. They surveyed 187 children ages 9 to 11 from five
B r i t i s hs c h o o l sa n da d m i n i s t e r e da6 - i t e ms u r v e yu s i n g
fourtypesof6-pointscales(e.g., Very much 654321 Not
atall,Very much 123456 Notatall,etc.),randomizedfor
each child. In this study, the children leaned towards the
positivelywordedlabel,whetheritwasontheleftorright
side,butdidnotnecessarilyorienttothenumericratings.
This was different compared with their 2010 web-based
studywithadultswhoorientedtowardsboththepositively
wordedlabelandthedescendingnumericorder.
Morerecently,Maeda(2015)testedresponse-orderef-
fects using a web-based, 15-item survey given to 1,693
respondents, all over 18 years of age and residing in the
UnitedStates.Inthisresearch,hewentfurtherthanjustas-
cendinganddescendingorderdifferencesandstudiedthe
effects of vertical and horizontal presentations of Likert-
scaleresponseoptions.Hefoundnosignificantdifference
between horizontal and vertical layouts of response op-
tions; however, the horizontal layout of response options
resulted in left-side selection bias. From these findings,
Maeda(2015)favoredtheuseofverticallayoutofLikert-
scale response options over Barnette’s (2000) suggestion
of using both ascending- and descending-ordered scales
in the same survey instrument and over Nicholls et al.’s
(2006)recommendationofrandomlyassigninghalfoftheAsufficientamountofresearch
hasshownthat
descending-orderedresponse
scalesgeneratemorepositive
responsesfromrespondents
thanascending-orderedscales.
respondents to ascending order and the other half to de-
scendingorder.
In another recent study, Liu and Keusch (2017) com-
paredresponse-ordereffectsinself-administeredsurveys
and orally presented surveys. The researchers reviewed
dataobtainedfromanadultAmericanpopulationduring
the2012AmericanNationalElectionStudies.Thesurvey
questions measured respondents’ attitudes towards tradi-
tionalism, position of Blacks in society, and attitudes to-
wardsegalitarianism.Therespondentswererandomlyas-
signedtousea5-pointLikertscaleinascending( Disagree
strongly,Disagree somewhat ,Neither agree nor disagree ,
Agree somewhat ,Agree strongly ) or descending order, on
eitheraweb-basedsurveyoraface-to-faceinterview.The
researchers found significant acquiescent bias present in
responses from the group that used descending response
orderintheweb-basedsurvey,butnotintheface-to-face
survey (interview). The researchers attributed the lack of
response-directioneffectintheface-to-facesettingtothe
useofbothvisualandauditorycommunicationduringthe
interview.
Thestudiespresentedherecautionedsurveydesigners
tobeawareofresponse-ordereffectsassociatedwithleft-
side selection bias, acquiescence bias, or satisficing when
using paper- or web-based surveys. A sufficient amount
of research has shown that descending-ordered response
scalesgeneratemorepositiveresponsesfromrespondents
thanascending-orderedscales.
Some Research Shows Lack of Signiﬁcant
Impact from Response-Order Orientation
Notallresearchstudieshavesupportedresponse-orderef-
fectsinself-administeredsurveys,whetherpaper-basedor
web-based. For example, Dillman et al. (2005) analyzed
data collected from thousands of people in seven states
of the United States. The participants were asked to re-
spond to energy and natural-resource issues by selecting
o n eo fm u l t i p l ed i s c r e t eo ro r d i n a lc a t e g o r i e s .U p o nt h e
review of data collected from 33 experimental questions
12www.ispi.org •DOI: 10.1002/pﬁ •OCTOBER 2018
included in mailed surveys, the researchers found only
four experiments resulting in significant primacy effects
and two experiments showing significant recency effects.
Theremaining27experiments(82%)didnotrevealsignif-
icant response-order effects. Thus, the researchers found
little support to conclude that a response-order effect oc-
curredinmailedsurveys.
Earlier, we discussed Chan’s (1991) study with a Tai-
wanese sample that showed left-side bias resulting in
higher mean scores. Another Taiwanese sample showed
lack of impact from different directions of response or-
der. In Weng and Cheng’s (2000) study, the researchers
administered a paper-based, self-administered question-
nairewritteninMandarinandusedinChan’s(1991)study
to 368 junior high and 490 college students in Taiwan to
measure their personal distress. The students completed
thesurveytwice—oncewitharesponsescaleineitheras-
cending or descending order and a week later using a re-
sponsescaleineitherthesameresponseorderortheoppo-
site order. The researchers found that students’ responses
tothequestionswerenotaffectedsignificantlywhengiven
varying response orders, leading them to conclude that
changing scale order did not affect responses. They ex-
plained that their sample groups were highly motivated
to complete the survey and less likely to succumb to sat-
isficing, which contributed to the lack of response-order
effects in their findings. In addition, they pointed out the
importance of using clear question wording and keeping
respondentsmotivatedtocompletetheirsurvey.
Lack of response-order effects has been found in web-
based surveys as well. In the study by Christian, Parsons,
andDillman(2009)involvingover3,000collegestudents
in the United States, half the participants were issued 10
questions using 5-point Likert-type scales with response
options presented in descending order (e.g., from Very
satisfiedtoVery dissatisfied ) and the other half given the
same questions with response options in reverse order.
Their study also failed to yield significant differences
between the two survey conditions to conclude that the
response order affected how respondents chose their
options. The researchers did find, however, that respon-
dents selected their options more quickly when using
descending-orderedscales.
In another web-based study with a non-English-
speakingsample,Hofmansetal.(2007)asked156mostly
college-educated Dutch-speaking Belgians to complete a
web-basedsurveywitha5-pointLikertscale( Fully agree ,
Rather agree ,Neutral,Rather disagree ,Fully disagree ),
wheresomequestionswererepeatedinanothersectionof
th esa m es u rv ey ,u s i n gth e5 - po i n tLi k e rtsc al ei nth eo p -
positedirection.Theresearchersfoundsomeminordiffer-
encesindatadistributionbetweentherepeatedquestionsManystudiesrevealed
response-ordereffectsin
self-administeredsurveys,
especiallytheprimacyeffect,
associatedwithleft-side
selectionbias,acquiescence
bias,andsatisficing.
with different ordered scales; the most positive option,
Fully agree ,w a ss e l e c t e dm o r eo f t e nw h e ni ta p p e a r e do n
thefarleftside(descendingorder)thanwhenitwasonthe
farrightside(ascendingorder).However,itwasnotsuffi-
cienttomakeasignificantdifferenceintheaveragescores.
Nonetheless, the researchers emphasized the importance
of being aware of the potential impact of response-order
orientation.
SUMMARY
Practitioners, as well as researchers, often develop their
ownsurveyinstruments.Whendesigningstructuredsur-
veyitemswithresponsescales,itisimportanttobeaware
of the impact that the response order may make on the
datatobecollected.
Many studies revealed response-order effects in self-
administered surveys, especially the primacy effect, asso-
ciatedwithleft-sideselectionbias,acquiescencebias,and
satisficing.Theresponse-ordereffectshavebeenshownin
both paper- andweb-basedsurveys, with adult and child
respondents, speaking English or other languages. In ad-
dition,manystudiesshowedmorepositiveaveragescores
fromdescending-orderedscales.Basedontheresearchev-
idence,itseemsobvioustousthatasimplesolutiontothe
inflated data obtained from descending-ordered scales is
topresentresponsescalesinascendingorder.Theascend-
ing order orientation is also aligned with a number line
showingnegativenumbersontheleftside,positivenum-
bersontherightside,andzerointhemiddle(e.g.,–2,–1,
0,+1,+2),whichisoftenchangedto1,2,3,4,and5when
codifyingthedataforstatisticalanalysis:
Strongly disagree (1) Disagree (2) Neutral (3) Agree
(4) Strongly agree (5)
Ifdescending-orderedscalesmustbeused,somestrate-
giescanbeemployedtoreducetheresponse-ordereffects:
Performance Improvement •Volume 57 •Number 9 •DOI: 10.1002/pﬁ 13
|TABLE 1RESEARCH EVIDENCE FOR THE USE OF ASCENDING OR DESCENDING ORDER OF LIKERT-TYPE
RESPONSE OPTIONS
FOCUSAUTHORS
(YEAR) RESEARCH FINDINGS AND RECOMMENDATIONS
Ascending order
signiﬁcantly
affects survey
resultsBarnette (2000) •Using positively worded items with bidirectional response scales (half SDtoSA,
and half SAtoSD) produced a higher level of reliability.
•A way to reduce acquiescence or response-set bias without mixing positively and
negatively stated items is to use only positively worded items with bidirectional
response scales (half SDtoSA, and half SAtoSD). Also, keep language simple
and questionnaires short.
Belson (1966) •In a test-room situation, the ﬁrst presented items tended to get greater endorsement
than when presented last, regardless of whether they were positive or negative
items.
•Since the response-order effects were found in the test-room situation, more studies
would be needed to show response-order effects in actual survey conditions.
Betts and Hartley
(2012)•Children were biased toward positive wording on the left side, regardless of the
numbers associated with the words ( Very much 6… 1 N o ta ta l l ;Very much 1…
6N o ta ta l l ).
•Take into consideration how children orient toward wording (but not numbers)
when designing surveys for children.
Chan (1991) •Evidence supporting the primacy effect was found in the surveys administered with
a Taiwanese sample.
•Researchers should be aware that reverse-coded scores may differ from the raw
scores.
Friedman et al.
(1993)•Positively stated items with descending-ordered scales resulted in a greater degree
of agreement (left-side selection effect), but the same effect did not occur in
negatively stated items with descending-ordered scales.
•Response scales in ascending order can keep respondents more attentive to the
scales and reduce acquiescence bias and satisﬁcing.
Hartley and Betts
(2010)•Adults were biased toward positive wording associated with higher numbers
presented on the left side of the scale ( Clear 10 … 0 Unclear ), resulting in higher
ratings.
•Be aware that the formatting of response scales can inﬂuence respondents to give
different ratings.
Liu and Keusch
(2017)•In the web setting, response scales presented in descending order signiﬁcantly
increased acquiescent responses, likely due to satisﬁcing.
•Be aware that seemingly trivial survey design features such as response order can
inﬂuence responses.
Maeda (2015) •With evidence of left-side selection bias, horizontally presented
descending-ordered response scales showed higher ratings. This effect did not
occur in vertically presented response scales.
•Use vertically presented response scales for making absolute judgments;
horizontally presented response scales can be used when making relative
judgments.
Nicholls et al.
(2006)•Descending-ordered response scales generate higher satisfaction levels.
•To control left-side selection bias, create two survey forms; have half of
respondents use a survey with all ascending-ordered response scales and another
half use a survey with all descending-ordered response scales.
No signiﬁcant
response order
effectsC h r i s t i a ne ta l .
(2009)•Ascending-ordered scales did not inﬂuence respondents’ selection of options.
However, visual layouts of response scales affected response time. Participants
were quicker to respond to items when their layouts were as expected.
•Accordingly, consider responder burdens such as response time when designing
the formats of response scales.
(Continued)
14www.ispi.org •DOI: 10.1002/pﬁ •OCTOBER 2018
|TABLE 1 Continued
FOCUSAUTHORS
(YEAR) RESEARCH FINDINGS AND RECOMMENDATIONS
Dillman et al.
(2005)•Little evidence was found to support primacy effects in mailed surveys and recency
effects in verbal surveys.
•Despite survey mode, be aware that social-desirability bias could inﬂuence the
primacy effect if socially desirable options are presented ﬁrst.
Hofmans et al.
(2007)•No signiﬁcant differences were found in average scores, whether ascending- or
descending-ordered scales were used. However, the Fully agree option was
selected more often when it was presented on the far left side than when it was
presented far right side.
•Therefore, it is important to be aware of the impact of response-order orientation.
Weng and
Cheng (2000)•Response order had no substantial effects on participant responses.
•To minimize response-order effects, use clear unambiguous wording and motivate
participants.
•Keep respondents motivated to complete the survey
withtheiraccurateanswers.
•Present half of survey items with descending-ordered
scales and the other half with ascending-ordered
scales.
•Assign half of participants to use descending-ordered
scales and the other half to use ascending-ordered
scales.
•Present response options vertically rather than
horizontally.
Table 1 provides a summary of the research evidence
usedingeneratingourrecommendations.
References
Barnette,J.(2000).EffectsofstemandLikertresponseoption
reversalsonsurveyinternalconsistency:Ifyoufeeltheneed,
thereisabetteralternativetousingthosenegativelyworded
stems.EducationalandPsycho logicalMeasurement ,60(3),
361–370.https://doi.org/10.1177/00131640021970592
Belson,W.A.(1966).Theeffectsofreversingthepresentation
orderofverbalratingscales. Journal of Advertising Research ,6
(December),30–37.
Betts,L.,&Hartley,J.(2012).Theeffectsofchangesintheorder
ofverballabelsandnumericalvaluesonchildren’sscoreson
attitudeandratingscales. BritishEducationalResearchJournal ,
38(2),319–331.https://doi.org/10.1080/01411926.2010.
544712
Callegaro,M.(2008).Socialdesirabilitybias.InP.J.Lavrakas
(Ed.),Encyclopediaofsurveyresearchmethods (vol.2,pp .
825–826).ThousandOaks,CA:SAGE.Retrievedfromhttp://link.galegroup.com/apps/doc/CX3073300551/GVRL?
u=bois91825&sid =GVRL&xid =4c1505a1
Chan,J.(1991).Response-ordereffectsinLikert-typescales.
EducationalandPsycho logicalMeasurement ,51(3),531–540.
https://doi.org/10.1177/0013164491513002
Christian,L.M.,Parsons,N.L.,&Dillman,D.A.(2009).
DesigningscalarquestionsforW ebsurveys. Sociological
Methods & Research ,37(3),393–425.
https://doi.org/10.1177/0049124108330004
Chyung,S.Y.,Barkin,J.,&Shamsy,J.(2018).Evidence-based
surveydesign:Theuseofnegatively-wordeditemsinsurveys.
PerformanceImprovement ,57(3),16–25.
https://doi.org/10.1002/pfi.21749
Chyung,S.Y.,Roberts,K.,Swanson,I.,&Hankinson,A.(2017).
Evidence-basedsurveydesign:Theuseofamidpointonthe
Likertscale. PerformanceImprovement ,56(10),15–23.
https://doi.org/10.1002/pfi.21727
Chyung,S.Y.,Swanson,I.,Roberts,K.,&Hankinson,A.(2018).
Evidence-basedsurveydesign:Theuseofcontinuousrating
scalesinsurveys. PerformanceImprovement ,57(5),38–48.
https://doi.org/10.1002/pfi.21763
Dillman,D.A.,Brown,T.L.,Carlson,J.E.,Carpenter,E.H.,
Lorenz,F.O.,Mason,R.,Saltiel,J.,&Sangster,R.L.(1995).
Effectsofcategoryorderonanswersinmailandtelephone
surveys.RuralSociology ,60(4),674–687.
https://doi.org/10.1111/j.1549-0831.1995.tb00600.x
Dillman,D.A.,&Christian,L.M.(2005).Surveymodeasa
sourceofinstabilityinresponsesacrosssurveys. FieldMethods ,
17(1),30–52.https://doi.org/10.1177/1525822X04269550
Friedman,H.H.,Herskovitz,P.J.,&Pollack,S.(1993).The
biasingeffectsofscale-checkingstylesonresponsetoaLikert
Performance Improvement •Volume 57 •Number 9 •DOI: 10.1002/pﬁ 15
scale.InProceedingsoftheAmericanStatisticalAssociation
annualconference: Surveyresearchmethods (vol.2,pp .
792–795).
Hartley,J.,&Betts,L.(2010).Fourlayoutsandafinding:The
effectsofchangesintheorderoftheverballabelsand
numericalvaluesonLikert-typescales. InternationalJournalof
SocialResearchMethodology ,13(1),17–27.
https://doi.org/10.1080/13645570802648077
Hofmans,J.,Theuns,P.,Baekelandt,S.,Mairesse,O.,
Schillewaert,N.,&Cools,W.(2007,June).Biasandchangesin
perceivedintensityofverbalqualifierseffectedbyscale
orientation. SurveyResearchMethods ,1(2),97–108.
https://doi.org/10.18148/srm/2007.v1i2.79
Holbrook,A.(2008a).Responseordereffects.InP.J.Lavrakas
(Ed.),Encyclopediaofsurveyresearchmethods (vol.2,pp.
754–756).ThousandOaks,CA:SAGE.Retrievedfrom
http://link.galegroup.com/apps/doc/CX3073300502/GVRL?
u=bois91825&sid =GVRL&xid =055a14c9
Holbrook,A.(2008b).Acquiescenceresponsebias.InP.J.
Lavrakas(Ed.), Encyclopediaofsurveyresearchmethods (vol.1,
pp.3–4).ThousandOaks,CA:SAGE.Retrievedfrom
http://link.galegroup.com/apps/doc/CX3073300015/GVRL?
u=bois91825&sid =GVRL&xid =ba24d6ea
Holbrook,A.L.,Krosnick,J.A.,Moore,D.,&Tourangeau,R.
(2007).Responseordereffectsindichotomouscategorical
questionspresentedorally. PublicOpinionQuarterly ,71(3),
325–348.https://doi.org/10.1093/poq/nfm024
Krosnick,J.A.(1991).Responsestrategiesforcopingwiththe
cognitivedemandsofattitudemeasuresinsurveys. Applied
CognitivePsychology ,5(3),213–236.https://doi.org/10.1002/
acp.2350050305Krosnick,J.A.,&Alwin,D.(1987).Anevaluationofacognitive
theoryofresponse-ordereffectsinsurveymeasurement. The
PublicOpinionQuarterly ,51(2),201–219.https://doi.org/
10.1086/269029
Liu,M.,&Keusch,F.(2017).Effectsofscaledirectionon
responsestyleofordinalratingscales. Journal of Official
Statistics,33(1),137–154.https://doi.org/10.1515/jos-2017-
0008
Maeda,H.(2015).Responseoptionconfigurationofonline
administeredLikertscales. InternationalJournalofSocial
ResearchMethodology ,18(1),15–26.
https://doi.org/10.1080/13645579.2014.885159
Nicholls,M.E.,Orr,C.A.,Okubo,M.,&Loftus,A.(2006).
Satisfactionguaranteed:Theeffectofspatialbiaseson
responsestoLikertscales. PsychologicalScience ,17(12),
1027–1028.https://doi.org/10.1111/j.1467-9280.2006.
01822.x
Schwarz,N.,&Oyserman,D.(2001).Askingquestionsabout
behavior:Cognition,communication,andquestionnaire
construction. AmericanJournalofEvaluation ,22(2),127–160.
https://doi.org/10.1177/109821400102200202
Tourangeau,R.(1984).Cognitivescienceandsurveymethods.
InT.B.Jabine,M.L.Straf,J.M.Tanur,&R.Tourangeau(Eds.),
Cognitiveaspectsofsurveymethodology:Buildingabridge
betweendisciplines (pp.73–100).Washington,DC:National
Academy Press.
Weng,L.,&Cheng,C.(2000).Effectsofresponseorderon
Likert-typescales. Educa tional&PsychologicalM easuremen t ,
60(6),908–924.https://doi.org/10.1177/001316400219
70989
SEUNG YOUN (YONNIE) CHYUNG, EdD., is a professor in the Department of Organizational
Performance and Workplace Learning in the College of Engineering at Boise State University
(http://opwl.boisestate.edu/faculty-staff/faculty/yonnie-chyung/). She teaches graduate courses on Pro-
gram Evaluation and Quantitative Research in Organizations. She runs a Workplace-Oriented Research
Central (WORC) lab where teams of practitioners and researchers conduct research on various topics in
the HPI context. She may be reached at ychyung@boisestate.edu
MEGAN KENNEDY is a graduate assistant in the Department of Organizational Performance and Work-
place Learning in the College of Engineering at Boise State University. She has been working with Dr. Chyung
to study evidence-based recommendations for survey design. She is also a student working on her MS in
the Department of Organizational Performance and Workplace Learning in the College of Engineering at
Boise State University. She may be reached at megankennedy@boisestate.edu
INGRID CAMPBELL is a technology tool specialist with the Online Programs Department in the Chap-
man Graduate School of Business at Florida International University. She holds a master’s degree in
Industrial/Organizational Psychology and is currently a student working toward the completion of a
Graduate Certiﬁcate in Workplace Instructional Design at Boise State University. She may be reached at
icampbel@ﬁu.edu
16www.ispi.org •DOI: 10.1002/pﬁ •OCTOBER 2018

## 2. Kluczowe cytaty

(Do selekcji manualnej z pełnego tekstu powyżej – fragmenty dotyczące order effects, rekomendacji, badań empirycznych.)

## 3. Wnioski dla projektu

- Przy pytaniach Likerta preferować **rosnący porządek** odpowiedzi (negatywne → pozytywne) przy układzie poziomym, aby zredukować bias po stronie lewej (primacy/left-side bias).  
- Układ pionowy minimalizuje różnice między kolejnością rosnącą i malejącą.  
- W kontekście ankiet wielojęzycznych i dla grup o zróżnicowanych kompetencjach cyfrowych układ pionowy może być bezpieczniejszym wyborem.  
- Warto stosować testy A/B porządku odpowiedzi w fazie pilotażowej ankiety.  

## 4. Komentarz krytyczny

Dla naszego projektu oznacza to, że w wersji testowej ankiety możemy sprawdzić zarówno układ rosnący, jak i malejący, ale w wersji docelowej powinniśmy trzymać się jednego, przemyślanego schematu. W ankietach dostępnych offline (np. papierowych lub na prostych urządzeniach) układ pionowy może być lepszy, bo ogranicza wpływ kierunku czytania i ograniczeń interfejsu.

