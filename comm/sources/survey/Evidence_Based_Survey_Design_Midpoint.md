# Evidence-Based Survey Design: The Use of a Midpoint on the Likert Scale

**Autorzy:** Ingrid Campbell  
**Rok:** 2018  
**Źródło:** Research & Theory Bucket  
**Język:** EN  
**Słowa kluczowe:** Likert scale, midpoint, neutral option, survey design, measurement bias

## 1. Streszczenie

Boi se St ate Universit y
ScholarWorks
Organizational Performance and W orkplace
Learning Faculty Publications and P resentationsDepartme nt of Or ganizational Performance and
Workplace Learning
11-1-2017
Evidence-B ased S urvey D esign: The U se of a
Midpoint on the Li kert Scale
Seun g Youn (Y onnie ) Chyung
Boise S tate University
Katherine R oberts
UnitedHealth Gr oup
Ieva Swanson
Scottrade, I nc
Andrea H ankinson
Government of Al berta
This is the pe er reviewed version of the fo llowing article:
Chyung, S.Y., Roberts, K ., Swanson, I., & H ankinson, A . (2017). E vidence-Based Survey D esign: The U se of a M idpo int on the L ikert Scale .
Performance Improvement, 56 (10), 15-23.
which h as be en pub lished in fin al for m at do i:10.1002/pfi .21727 . Thi s article m ay be us ed for non-c omme rcial pur poses in a ccordance with W iley
Terms and C ond itions for S elf-Archiv ing.
brought to you by CORE View metadata, citation and similar papers at core.ac.uk
provided by Boise State University - ScholarWorks
Evidence- Based Survey Design:  
The Use of a Midpoint on the Likert Scale  
 
Seung Youn (Yonnie) Chyung  
Boise State University  
Boise, ID  
 
Katherine Roberts  
Nicholasville, KY  
 
Ieva Swanson  
St. Louis, MO  
 
Andrea Hankinson  
Public Service Commission  
Government of  Alberta  
Edmonton, AB, CA  
 
 
Introduction  
 One of the most popular response scales used in survey design is the Likert scale. In the 1930s, Rensis Likert, an 
American social psychologist, first introduced a five -point psychometric scale for measuring a seri es of attitude -
related propositions (Likert, 1932). The wording used in the initial Likert scale was: Strongly Approve , Approve , 
Undecided , Disapprove , and Strongly Disapprove . Over time, the wording changed from Approve  to Agree , which 
resulted in the Likert scale we know today: Strongly Agree  and Agree  on one side, and Disagree  and Strongly Disagree  
on the other side,  with a midpoint in the middle.  
 
Due to its simplicity and popularity, the traditional Likert scale expanded into many variations of Likert -type scales. 
These are commonly used in survey instruments designed for: measuring employee performance in the workplace (Purdey, 2013), communications research (Ryan, 1980), marketing research (Garland, 1991), political opinion 
research (Raaijmakers, van Hoof, ‘t Hart, Verbogt, & Vollebergh, 2000), and psychometric research ( Kulas & 
Stachowski, 2013). Its popularity, however, does not necessarily equate to its validity as a data collection method (Johns, 2005). Debates over validity arise from the variatio ns in Likert -type scales in the context of these applications. 
That is, what are the impacts of:  
• Including or not including a midpoint in the scale? e.g.,  
o Strongly Disagree, Disagree, Neutral, Agree, Strongly Agree  
o Strongly Disagree, Disagree, Agree, Strongly Agree  
• Using descending order vs. ascending order of the scale options? e.g.,  
o Strongly Agree , Agree, Neutral, Disagree, Strongly Disagree  
o Strongly Disagree, Disagree, Neutral, Agree, Strongly Agree  
• Measuring positively-  and negatively- stated survey items with the Likert scale ? e.g., 
o The objectives were clear  
Strongly Disagree, Disagree, Neutral, Agree, Strongly Agree  
o The objectives were unclear  
Strongly Disagree, Disagree, Neutral, Agree, Strongly Agree  
o The objectives were not clear  
Strongly Disagre e, Disagree, Neutral, Agree, Strongly Agree 
  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
1 
• Using Likert -type scales or slider scales?  e.g., 
o Completely Dissatisfied 0 1 2 3 4 5 6 7 8 9 10 Completely Satisfied 
o  
 
There is a vast amount of research on these topics, and each topic is worth a separate article. The purpose of this article 
is to 1) provide an overview of the Likert scale’s characteristics as a measurement method, and 2) present research -
based evidence and recommendations regarding the use of a midpoint on Likert -type scales.  
 
The Likert Scale as a Measurement Method  
 
Types of Measurement  
 
To understand the characteristics of the Likert scale as a measurement method, we need to understand different types 
of measurement. In the 1940s, Stanley Smith Stevens, another American psychologist, formulate d four types (levels) 
of measurement: nominal, ordinal, interval, and ratio scales (Stevens, 1946). Simply put, the nominal scale contains names of equal quality [e.g., the six cells in Thomas Gilbert’s (1996) Behavior Engineering Model —Data , 
Instruments , Incentives , Knowledge , Capacity , Motives ]; the ordinal scale contains rank -ordered levels (e.g., 
performance ratings such as Poor , Fair, Good ); the interval scale contains levels with equal intervals (e.g., a scale 
consisting of -2, -1, 0, 1, 2); and the r atio scale contains levels with equal ratios and a meaningful zero value (e.g., test 
scores of zero to 100) . 
 The Likert scale measures attitudes using five points (anchors) where the third point in the middle represents neutrality. 
Whether the Likert scale is an ordinal scale or an interval scale has been an ongoing debate among researchers. For 
the Likert scale to be an interval scale, the distances between consecutive points on the scale must be the same, as 
shown in Figure 1 . That is, the distance between St rongly Disagree  and Disagree  (the length of “a” in Figure 1 ) is the 
same as the distance between Disagree  and Neutral  (“b”), which is the same as the d istance between Neutral  and 
Agree  (“c”), as well as the distance between Agree  and Strongly Agree  (“d”).  
 
 
Figure 1. The five -point Likert scale assumed as an interval scale.  
 
On the other hand, the distances between two consecutive points on the Likert scale (“a,” “b,” “c,” and “d”) may be 
different, as shown in Figure 2 . This disqualifies the Likert scale from serving as an interval scale, but characterizes 
it as an ordinal scale.  
 
 
Figure 2. The five -point Likert scale as an ordinal scale.  
 
Also, it is important to word a midpoint appropriately.  For instance, Neutral  (or Neither Agree nor Disagree ) as a 
midpoint represents a neutral level of opinion. If, however, Undecided  is used for the midpoint, it is questionable 
whether it is truly a midpoint of opinion between disagreement and agreement, or if it should be treated as an absence 
of opinion. In the latter case, the Likert scale is more like a four -point ordinal scale with Undecided  as a separate 
option off the scale, as illustrated in Figure 3 . To collect data that is more likely to be interval than ordinal in nature, 
the use of other opinions such as I don’t know  or It depends  should not label a midpoint, but could be presented as 
response options off the scale.  
 
 
Figure 3. The four point ordinal Likert scale with Undecided as a separate option.  
 
This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
2 
So What If the Liker t Scale is an Interval or Ordinal Scale?  
 
Why does it matter if the Likert scale is an interval scale or an ordinal scale? A more appropriate question to ask is, 
“When  does it matter?” It matters when we intend to calculate average scores and perform certain statistical analyses 
on the data collected from the Likert scale. Depending on whether the Likert scale is an ordinal or interval scale, you 
are limite d, or open, to employing certain types of data analysis methods.  
 
A four -point Likert scale is an ordinal scale (as shown in Figure 3 ). Unlike an inter val scale, an average score of “2.5” 
obtained from a four -point Likert scale has as little meaning as a score of “fair and a half” from a scale labeled poor , 
fair, good, and excellent (Kuzon, Urbanchek, &  McCabe, 1996, p. 266). With ordinal data, one should use median or 
mode, rather than the mean, as the measure of central tendency, and describe a summary of ordinal data with frequencies or percentages of responses in each category (Jamieson, 2004). In ad dition, certain statistical analyses 
(such as parametric tests, like an independent samples t  test or Pearson correlation r ) require using normally distributed 
data likely obtained from interval or ratio scales. When data are obtained from ordinal scales s uch as a four -point 
Likert scale ( Figure 3 ) or do not meet the normality assumption, you would use non -parametric tests such as Chi -
Square (cross -tabulation), Mann -Whitney U, or Spearman rho.  
 The five -point Likert scale can be an ordinal scale as illustrated in Figure 2 ; however, it is often treated  as an interval 
scale as shown in Figure 1 . Proponents of treating the five -point Likert scale as an interval scale argue that since in 
practice, it is common to use a group of multiple items measured with the Likert scale. Thus, it is “perfectly appropriate 
to summarise  the ratings generated from Likert scales using means and standard deviations, and it is perfectly 
appropriate to use parametric techni ques like Analysis of Variance to analyse Likert scales” (Carifio & Perla, 2008,  
p. 1151).  
 
The difference between a four -point Likert scale and a five -point Likert scale is whether or not a midpoint is included. 
The presence of a midpoint makes a differen ce in treating the scale as an interval scale only if survey respondents use 
the Likert scale midpoint for a true neutral meaning, as intended. In turn, the assumption of an interval scale influences 
the decision for using appropriate descriptive statistic s among mean, median, mode, standard deviation, frequency, 
and percentage, and employing appropriate types of inferential statistical analyses. In the following sections, we will discuss research findings associated with respondents’ use of a midpoint in t he Likert scale and evidence- based 
recommendations for designing survey items with the Likert scale.  
 
Research Findings on the Use of a Midpoint on Likert Type Scales  
 
How Do Respondents Interpret and Use a Midpoint?  
 
In structured survey questionnaires, response scales such as the Likert scale are used “to allow respondents to express 
both the direction and strength of their opinion about a topic” (Garland, 1991, p. 66). You insert a midpoint on the 
Likert scale to all ow respondents to express a neutral opinion between disagreement on one side and agreement on 
the other. When you present an equal number of options on both the disagreement and agreement sides, including or 
excluding a midpoint makes the scale an odd -numbered or even -numbered scale (e.g., a five- point or six- point scale). 
Likert -type scales without a midpoint are also characterized as forced -choice scales,  as respondents are forced to 
choose either a disagreement or agreement option. For a midpoint of neut rality, neutral  or neither agree nor disagree  
are often used.  
 Research has shown, however, that respondents do not always interpret and use a midpoint in the way that scale developers intended. Respondents might select a midpoint even if their true opinio n is not neutral. In Kulas and 
Stachowski’s (2009) research, the researchers asked 82 college students to complete survey items with a five- point 
Likert scale (with Neither agree nor disagree  as a midpoint) and also with four options: It depends, Uncertain, 
Average, and Not applicable . Of the four options, respondents who did select the midpoint most commonly chose It 
depends  (a 50% probability).  
 Another concern is that respondents may use a midpoint as a dumping ground when they are responding to survey 
items that are unfamiliar to them, or items that are ambiguous or socially undesirable. In Nadler, Weston, and Voyles’ 
(2015) study, 635 college students described how they would interpret the midpoint Neither agree nor disagree  on a 
five-point Likert scale . Researchers organized their interpretations into 16 different themes. Some of the themes are:  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
3 
• Unsure (13%), Undecided (8%), Confused (2%), or Need more information (2%)  
• Neutral (10%), Neither (9%), or Middle point (4%)  
• No opinion (15%)  
• Don't care (14%)  
• Both agree and disagree (10%)  
• Not applicable (3%)  
 
Age also seems to influence the use of a midpoint. Raaijmakers, et al. (2000) conducted political opinion research with younger respondents: 3,220 Dutch youths aged 12- 24 years in 1991 and 1,887 youths in 1994. The respondents 
completed survey items with a five -point Likert scale accompanied by a Don’t know  option. The researchers found 
that younger adolescents used the Don’t know  option or did not respond considerably more often than older 
respondents. As age increased, Don’t know  responses and non- responses decreased while midpoint responses 
increased. The researchers attributed this to social desirability bias , which explains that respondents may select an 
option that they perceive to be more socially accepted or desirable. That is, selecting a midpoint could be viewed as more socially desirable than selecting a Don’t know  option or leaving it blank.  
 
Garland (1991) made a similar observation about social desirability bias in marketing research he conducted with 
public grocery shoppers (age 15 or older), using a four -point scale (n=223) and a five -point scale (n=225). He found 
that 14% of the five -point  scale respondents who selected the midpoint (neither/nor) chose a negative option when the 
midpoint was absent from the scale. In other words, a considerable number of respondents selected a midpoint to avoid 
what they perceived as a socially undesirable behavior by selecting a negative option.  
 
With the popularity of web -based surveys increasing, respondent expectations that the survey will require a response 
to each item may create response tendencies  to complete all items. This creates situations where respondents feel 
compelled to answer questions about which they have no opinion and where they use the midpoint as an out. In Kulas, 
Stachowski, and Haynes’ (2008) study, 118 college students completed an online survey of a personality assessment 
with a fi ve-point Likert scale (the traditional form) and completed it again with a five -point Likert scale with an 
additional N/A option (the N/A form). Researchers found an overwhelming tendency for respondents to choose the 
midpoint on the traditional form if th ey chose N/A on the same item in the N/A form.  
 
Should You Use a Midpoint or Not?  
 
These researched problems associated with the use of a midpoint in response scales bring up a question as to whether 
we should use a midpoint in survey instruments (i.e., whether to use odd- numbered or even -numbered scales). Simply 
omitting a midpoint from  the scales, however, is not the best practice. The more important question that practitioners 
and researchers should seek to answer is not whether or not to include a midpoint, but rather when  to omit or present 
a midpoint in a Likert- type scale.  
 
For ins tance, research conducted by Matell and Jacoby (1972) with 360 college students revealed that more 
respondents selected the midpoint ( Uncertain ) on a five -point scale than on 17 other Likert -type scales varying in the 
number of anchors (from two to 19 anch ors), while the average completion time was shorter for the five -point scale 
than for other scales (excluding the two -point scale). The fact that many respondents quickly selected the midpoint on 
the five -point can be explained as satisficing behavior : cho osing a minimally acceptable response as soon as it is 
found, instead of putting effort to find an optimal response. Based on their findings, the researchers recommended that when survey designers need to minimize the misuse of a midpoint, it is better to omit the midpoint on coarse scales 
(scales with few anchors) or increase scale sensitivity (by using many anchors) when including a midpoint.  
 
It may be also desirable to omit a midpoint and offer instead an I don’t know  option when respondents are comfort able 
with the survey topic (they have formed their opinions), when they are under strong social desirability pressures (John, 2005), or when it is expected that some respondents have little or no involvement in the survey topic (Weems & 
Onwuegbyzie, 2001).  
 
  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
4 
On the other hand, including a  midpoint gives respondents the opportunity to express a neutral opinion, especially on 
obscure topics (Johns, 2005). A midpoint can also improve psychometric properties such as instrument reliability 
(Adelson & McCoach, 201 0). You can reduce the potential misuse of a midpoint as an ‘N/A proxy’ or ‘dumping 
ground’ by first improving clarity of survey items ( Kulas & Stachowski, 2013) and  presenting other options off the 
scale such as Not applicable , I don’t know , or It depends  (Kulas, et al., 2008; Raaijmakers, et al., 2000). Table 1 
presents a summary of the evidence- based recommendations based  on the literature we reviewed.  
 
Another reason for including a midpoint in the Likert scale is to use it as an interval scale and thus  apply appropriate 
statistical analyses, as discussed earlier. Including a midpoint in the Likert scale, however, has raised discussions on 
how it affects validity and reliability of the survey instrument.  
 
Table 1. Evidence -Based R ecommendations on the Use of a Midpoint on the Likert Scale  
 Include a Midpoint  
(Strongly Disagree, Disagree, Neutral, Agree, 
Strongly Agree ) Omit a Midpoint  
(Strongly Disagree, Disagree, Agree, Strongly 
Agree ) 
Benefit  • It allows respondents to express their true 
neutral/indifferent opinion; respondents are 
not forced to agree or disagree.  • Eliminates the possibility that respondents 
will misuse the midpoint.  
Problem  • Respondents may use the midpoint as a 
dumping ground when:  
o They don’t know enough about the 
content asked in the survey 
o They are ambivalent about the topic  
o They don’t care about the topic  
o They think their answer depends on 
other factors  
o They want to provide the responses that 
are more socially acceptable  • Respondents are not provided with an 
opportunity to express their neutral opinion.  
• Forcing respondents to take a side may 
produce biased data.  
When  • Respondents are familiar with the topic and 
should be allowed to express a neutral 
opinion.  
• It is important to use the scale as an interval 
scale for the statistical analysis purpose.  • Respondents are:  
o Unfamiliar or uncomfortable with the survey topic  
o Not expected to have formed their 
opinion about the topic  
o Under strong social desirability 
pressures  
o Likely to show satisficing behavior  
Strate gies 
to Use  • Improve clarity of survey items as 
respondents tend to select a midpoint when 
they are uncertain about the meaning of the items.  
• Present additional options such as Not 
applicable , I don’t know , or It depends . • Offer an I don’t know  or Not applic able 
option instead of forcing respondents to 
choose an option.  
 
Does a Midpoint Affect Validity and Reliability of the Scales?  
 To generate accurate and reliable data, survey designers need to be sure that their survey items actually measure what 
the designers intended to measure (validity). To test for consistency (reliability), designers will use a set of multiple 
related survey items. As discussed earlier, presence of a midpoint can promote satisficing behavior and social 
desirability bias. Responde nts may interpret and use a midpoint as a dumping ground or an easy way out (Kulas & 
Stachowski, 2009), or select a midpoint rather than selecting socially undesirable options (Garland, 1991; Raaijmakers, et al., 2000). Another example is  Guy and Norvell’s  (1977) study with 200 college students using a five -
point Likert scale with a midpoint and a four -point Likert scale without it. They found that when a midpoint was 
absent, the midpoint responses were not only distributed to the neighboring options, but t here were also increased 
numbers of non- responses. One of the findings was:  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
5 
• When a midpo int was present -  SA (205), A (422), N (291), D (402), SD (178), No response (2)  
• When a midpoint was omitted -  SA (127), A (568), D (573), SD (202), No response (30)  
Based on the fact that the number of no responses increased from two to 30, it is plausible that some of the people 
who selected the midpoint when it was present did not use it for a true neutral meaning. These are potential threats to 
instrument validity an d reliability.  
 On the other hand, other studies did not find that the presence and absence of a midpoint affected instrument validity 
and reliability differently. In Adelson and McCoach’s (2010) study with 606 children (grades three -six), researchers 
tested the validity of a two -factor model of the instrument by using a five -point Likert scale with a midpoint and a 
four-point Likert scale without it. Regardless of whether a midpoint was present or not, they found a good model fit 
for the instrument; howeve r, the use of a five -point Likert scale resulted in a significantly higher reliability estimate 
for the instrument. Alwin and Krosnick (1991) also observed a pattern of increased reliability with an increasing 
number of anchors (from three to four, to seve n, and to nine) in response scales, although the reliabilities of the four -
point and five -point scales were not significantly different from each other . 
 In Leung’s (2011) study with 1,217 secondary school students (13- 18 years of age) in Macau, the presen ce of a 
midpoint in the five - and 11- point scales compared to the four - and six -point scales without a midpoint did not make 
any differences in factor loadings (a measure of construct validity) and Cronbach’s alpha (a measure of reliability). 
The six-  and 11-point scales, however, produced data that met the normality assumption while the data obtained from 
the four - and five -point scales did not.  
 In Kulas, et al.’s (2008) study with college students discussed earlier, researchers found no significant difference in 
variance and reliability estimates of data obtained from the traditional form with a five -point Likert scale and the N/A 
form with a five -point Likert scale and an additional N/A option. However, the researchers warned that the lack of 
effect on r eliability and validity estimates could have been due to the low frequency of the overall N/A respo nses.  
 
As shown above, there has been inconsistent evidence regarding the impacts of inclusion of a midpoint on validity 
and reliability. Krosnick and Fabrig ar (1997) also indicate that experimental studies have failed to show a clear pattern 
in the effects of a midpoint on scale reliability. The research findings, however, seem to point to another issue to 
consider: the number of anchors used in response scal es. 
 
How Many Anchors Should You Use?  
 When determining the number of anchors in response scales, the survey designer should consider various factors, 
including strategies to minimize potential biases, as illustrated earlier. Research has shown that, as the number of 
anchors increased, the use of a midpoint decreased; thus, it is better to use many anchors in scales when you need to discourage respondents’ use of a midpoint (Matell & Jacoby, 1972). Respondents may also prefer having a sufficient 
number of  options from which to choose. With 149 adults, Preston and Colman (2000) studied respondents’ 
preferences for response scales based on three criteria: 1. Was easy to use, 2. Was quick to use, and 3. Allowed 
adequate expression of feelings. The response scales differed in the number of options included (2, 3, 4, 5, 6, 7, 8, 9, 
10, 11, and 101) and were end -anchored (e.g., Very poor  1 2 3 4 5 Very good ). The data showed that five -, seven -, and 
10-point scales were the easiest to use, while (unsurprisingly), two -, three -, and four -point scales were the quickest to 
use. On the other hand, respondents felt that the scales with more options (nine -, 10-, 11-, and 101- point scales) 
allowed them greater expression of feelings. The researchers concluded that overall,  the 10 -point scale scored best, 
followed by the seven -point and nine -point scales.  
 In contrast, Chang (1994) points to a problem in using many anchors in scales. By comparing the reliability of two 
even -numbered Likert scales, a four -point scale ( Disagree, Somewhat disagree, Somewhat agree, Agree ) and a six -
point scale ( Strongly disagree, Disagree, Somewhat disagree, Somewhat agree, Agree, Strongly agree ), the researcher 
found a tendency of respondents to skip categories in the six -point scale and an inability to differentiate between two 
similar categories such as Strongly disagree  and Disagree,  leading to a possibility that respondents may use the 
categories interchangeably.  
 
  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
6 
This leads to the impor tance of considering information processing issue s in survey design. Chen, Yu, and Yu (2015) 
conducted an eye -tracking experiment with a sample of 184 Chinese people to measure respondents’ reaction time in 
answering a question as evidence of their cognitive effort. They found that a five -point scale req uired the shortest 
reaction time, compared to four -, six-, seven -, eight -, and nine -point scales. Also considering the data showing 
potential acquiescence bias  (respondents’ tendency to choose positive options) and extreme response bias  
(respondents’ tende ncy to disproportionately select extreme responses), the researchers determined five as the optimal 
number of anchors, and emphasized keeping an optimal balance in the scale design in order to lower the respondents’ 
cognitive effort while maximizing the co mmunication o f information within the scale.  
 
Similarly, in a study with 1,207 male Dutch -speaking Internet users (aged from 15 to 65 with a median age of 49) 
comparing four -, five -, six -, and seven -point Likert -type scales, Weijters, Cabooter, and Schille waert (2010) 
concluded that including a midpoint resulted in lower levels of extreme responses, and that using fully labeled scales 
with a midpoint produced lower levels of mis -responses when reversed items were used. They recommended using 
fully labeled f ive-point scales  for the general population and fully labeled seven- point scales for populations with high 
levels of verbal skills and experience with using survey questionnaires.  
 Based on these research findings, it seems that the decision on the number of anchors to use should depend largely on 
what the survey designer deems important in terms of ways to lower the respondents’ cognitive effort and boost the 
ease of taking the survey, while allowing respondents to express their opinions sufficiently, espe cially when 
respondents are under time pressure. For these situations, the use of five - or seven -point scales is commonly suggested.  
 
Summary  
 
Over the last several decades, researchers studied the effects of the presence or absence of a midpoint in respon se 
scales on respondents’ behavior and discussed both benefits and challenges, as well as suggested ways to mitigate 
respondents’ potential misuse of a midpoint. The decision to enhance instrument reliability and validity by choosing 
to include or exclude a midpoint on the response scale cannot be easily isolated from other factors, such as scale 
sensitivity, age and education -level of respondents, absence/presence of a midpoint label, and choice of a midpoint 
label. When designing a scale, we suggest emplo ying the strategies discussed earlier to reduce response bias and the 
possibility of respondents misusing the midpoint as a catch -all. For your reference, Table 2 includes a summary of the 
research evidence used in generating our recommendations.  
 
  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
7 
Table 2. Research Eviden ce for the Use of a Midpoint on the Likert Scale.  
Focus  Authors (Year)  Recommendations Based on Research Findings  
Inclusion vs. 
exclusion of 
a midpoint  Garland (1991)  • Offering a midpoint is largely based on researchers’ preference  
• Social desirability bias can be minimized by omitting a midpoint  
Johns (2005)  • Omit a midpoint when respondents are comfortable with the subject 
matter, and under social desirability pressures  
• Vary formats within a questionnaire to increase respondents’ awareness  
Kulas, et al. 
(2008)  • Include an N/A option in addition to a midpoint, especially in online 
survey questionnaires  
Kulas and 
Stachowski 
(2009)  • Improve clarity of survey items  
• Offer an It depends  option  
Kulas and 
Stachowski 
(2013)  • Use a midpoint cautiously; improve clarity of survey items  
• Offer alternative I don’t know  or It depends  options  
Nadler, et al. 
(2015)  • Use a midpoint with caution; clearly define the meaning of a midpoint for 
respondents  
• Offer a No opinion  option and treat No opinion  as missing data  
Raaijmakers, et 
al. (2000)  • Do not remove a midpoint simply based on the problem associated with 
its dual meaning  
• Provide an I don’t know  option  
 Ryan (1980)  • Differentiate between I don’t know , Neutral , and No opinion  
• Neutral  is a definite opinion, while No opinion  is not  
Weems and 
Onwuegbyzie 
(2001)  • Omit a midpoint when respondents are less involved in the content  
• Provide other response categories (e.g., I d on’t know ) 
Validity and 
reliability of 
the 
instrument 
and the 
number of anchors  Adelson and 
McCoach (2010)  • Can use a five -point scale including a midpoint when surveying with 
children in Grades three to six.  
Alwin and 
Krosnick (1991)  • Be aware that response scales with more categories are more reliable; 
fully labeled seven -point scales are more reliable than those not so 
labeled; reliability does not improve by offering I don’t know  
Chang (1994)  • When using many anchors in scales, be a ware of respondents’ inability to 
differentiate between two similar categories such as Strongly disagree  
and Disagree  
Chen, et al. 
(2015)  • Keep an optimal balance in the scale design in order to lower the 
respondents’ cognitive effort while maximizing the communication of 
information within the scale  
• Use a five -point scale as it is the best option from an information -
processing perspective  
Guy and Norvell 
(1977)  • Be aware that if respondents are familiar with using a five -point scale, the 
use of a four -point scale may produce somewhat distorted data  
Leung (2011)  • Use a 11 -point scale for improved psychometric performance (meeting 
the norma lity assumption)  
Matell and 
Jacoby (1972)  • Use many anchors in scales when needing to minimize respondents’ 
(mis)use of a midpoint, as the number of anchors decreased, the use of a 
midpoint increased  
Preston and 
Colman (2000)  • Be aware of respondents’ preference toward having a sufficient number 
of options from which to choose; e.g., a 10- point scale, followed by 
seven -point and nine -point scales  
• Trade off reliability and validity if needed to improve factors such as 
respondent preferences  
Weijters, e t al. 
(2010)  • Use fully labeled five -point scales for the general population and fully 
labeled seven -point scales for populations with high cognitive skills  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
8 
References  
 
Adelson, J. L., & McCoach , D. B. (2010). Measuring the mathematical attitudes of elementary students: The effects 
of a 4 -point or 5- point Likert -type scale. Educational and Psychological Measurement, 70(5), 796 –807. 
doi:10.1177/0013164410366694  
Alwin, D. F., & Krosnick , J. A. (1991). The reliability of survey attitude measurement. In D. F. Alwin (Ed.), 
Sociological methods & research (Volume 20, Issue 2, pp. 139- 181). SAGE: Newbury Park.  
Carifio, J., & Perla, R. (2008). Resolving the 50 -year debate around using and misu sing Likert scales. Medical 
Education, 42 (12), 1150- 1152. doi:10.1111/j.1365- 2923.2008.03172.x  
Chang, L. (1994). A psychometric evaluation of 4- point and 6- point Likert -type scales in relation to reliability and 
validity. Applied Psychological Measurement,  18(3), 205 -215. 
Chen, X., Yu, H., & Yu, F. (2015). What is the optimal number of response alternatives for rating scales? From an 
information processing perspective. Journal of Marketing Analytics, 3(2), 69 -78. doi:10.1057/jma.2015.4  
Garland, R. (1991). T he mid -point on a rating scale: Is it desirable? Marketing Bulletin, 2 , 66-70. Available at: 
http://marketing -bulletin.massey.ac.nz/V2/MB_V2_N3_Garland.pdf  
Gilbert, T. F. (1996). Human competence: Engineering worthy performance  (Tribute ed.). Washington, D .C.: The 
International Society for Performance Improvement.  
Guy, R. F., & Norvell, M. (1977). The neutral point on a Likert scale. The Journal of Psychology, 95, 199- 204. 
Jamieson, S. (2004). Likert scales: How to (ab)use them. Medical Education, 38(12), 1217- 1218. doi:10.1111/j.1365-
2929.2004.02012.x  
Johns, R. (2005) One size doesn’t fit all: Selecting response scales for attitude items. Journal of Elections, Public 
Opinion and Parties, 15(2), 237 -264, doi: 10.1080/136898805001788  
Krosnick, J. A., & Fabriga r, L. R. (1997). Designing rating scales for effective measurement in surveys. In L. Lyberg, 
P. Biemer, M. Collins, E. De Leeuw, C. Dippo, N. Schwarz, & D. Trewin (Eds.), Survey measurement and 
process quality  (pp. 141- 164). New York: John Wiley & Sons, In c. doi:10.1002/9781118490013.ch6 
Kulas, J. T., & Stachowski, A. A. (2009). Middle category endorsement in odd- numbered Likert response scales: 
Associated item characteristics, cognitive demands, and preferred meanings. Journal of Research in Personality, 4 3(3), 489 -493. doi:10.1016/j.jrp.2008.12.005  
Kulas, J. T., & Stachowski, A. A. (2013). Respondent rationale for neither agreeing nor disagreeing: Person and item 
contributors to middle category endorsement intent on Likert personality indicators. Journal of Research in Personality, 47(4), 254 -262. doi:10.1016/j.jrp.2013.01.014  
Kulas, J., Stachowski, A., & Haynes, B. (2008). Middle response functioning in Likert -responses to personality items. 
Journal of Business & Psychology, 22(3), 251 -259. doi: 10.1007/s 10869- 008-9064- 2 
Kuzon, W. M., Urbanchek, M. G., & McCabe, S. (1996). The seven deadly sins of statistical analysis. Annals of 
Plastic Surgery, 37(3), 265 -272. 
Leung, S -O. (2011) A comparison of psychometric properties and normality in 4- , 5-, 6-, and 11- point Likert scales. 
Journal of Social Service Research. 37(4), 412- 421. doi:10.1080/01488376.2011.580697  
Likert, R. (1932). A technique for the measurement of attitudes. In R. S. Woodworth (Ed.), Archives of Psychology  
(Vol. 22, No. 140, pp. 5- 55). New York: The Science Press.  
Matell, M. S., & Jacoby, J. (1972). Is there an optimal number of alternatives for Likert -scale items? Effects of testing 
time and scale properties . Journal of Applied Psychology, 56(6), 506- 509. 
Nadler, J. T., Weston, R., & Voyles, E. C. (2015). Stuck in the middle: The use and interpretation of mid- points in 
items on questionnaires. The Journal of General Psychology, 142(2), 71- 89, 
doi:10.1080/00221309.2014.994590  
Preston, C. C., & Colman, A. M. (2000). Optimal number of response cate gories in rating scales: reliability, validity, 
discriminating power, and respondent preferences . Acta Psychologica, 104(2000), 1- 15. 
Purdey, B. (2013). Occupant stimulus response workplace productivity and the vexed question of a measurement. 
Workplace Pr oductivity, 31 (11), 505 -520. doi:10.1108/F -03-2012- 0021  
Raaijmakers, Q. A. W., van Hoof, a., 't Hart, H., Verbogt, T. F. M. A., & Vollebergh, W. A. M. (2000). Adolescents’ 
midpoint responses on Likert -type scale items: Neutral or missing values? International Journal of Public 
Opinion Research, 12(2), 208 -216. doi:10.1093/ijpor/12.2.209 
Ryan, M. (1980). The Likert scale's midpoint in communications research. Journalism Quarterly, 57(2), 305 -313. 
Stevens, S. S. (1946). On the theory of scales of me asurement. Science, 103 (2684), 677– 680. 
doi:10.1126/science.103.2684.677  
Weems, G, H., & Onwuegbyzie, A. J. (2001). The impact of midpoint responses and reverse coding on survey data. 
Measurement and Evaluation in Counseling and Development, 34(3), 166- 176. This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
9 
Weijters, B., Cabooter, E., & S chillewaert, N. (2010). The effect of rating scale format on response styles: The number 
of response categories and response category labels. International Journal of Research in Marketing, 
27(2010), 236- 247. 
 
Biographies  
 
Seung Youn (Yonnie) Chyung, Ed.D.,  is a Professor of the Department of Organizational Performance and 
Workplace Learning in the College of Engineering at Boise State University (http://opwl.boisestate.edu/faculty -
staff/faculty/yonnie -chyung/). She teaches graduate courses on Program Evaluation and Quantitative Research in 
Organizations. She runs a Workplace- Oriented Research Central (WORC) lab where teams of practitioners and 
researchers conduct research on var ious topics in the HPI context.  
 Katherine Robe rts is a Sr. Instructional Designer with WellMed under UnitedHealth Group’s umbrella in San 
Antonio, Texas. She is a graduate assistant for Dr. Seung Youn (Yonnie) Chyung and attends Boise State University 
as a graduate student in the Organizational Perfor mance and Workplace Learning program. She expects to complete 
her Master’s Degree in May of 2017.  
 Ieva Swanson, MS , is an Instructional Designer for Scottrade, Inc. in St. Louis, Missouri. Since 2007, her professional 
and volunteer experience has included  facilitation, instruction, learning management system administration, and multi -
media course design. She earned her MS in Organizational Performance and Workplace Learning from Boise State University in 2016 . 
 
Andrea Hankinson, MA, MS,  is the performance excellence consultant at the Public Service Commission, a 
department of the Government of Alberta, in Edmonton, Alberta, Canada. She holds a MS in Organizational Performance and Workplace Learning from Boise State University and an MA in English from Simon  Fraser 
University. She has worked extensively in online and distance learning and is a freelance writer and instructor of 
writing.  This is an author -produced, pee r-reviewed version of this article. The final, definitive version of this document can be found online at 
Performance Improvement , published by Wiley . Copyright restrictions may apply. doi: 10.1002/pfi.21727  
10

## 2. Kluczowe cytaty

(Do selekcji manualnej z pełnego tekstu powyżej – fragmenty dotyczące wpływu punktu środkowego, zaleceń projektowych, wyników badań.)

## 3. Wnioski dla projektu

- Obecność punktu środkowego (neutralnego) w skali Likerta może wpływać na wybory respondentów — część osób wybiera go z powodu rzeczywistej neutralności, inni z powodu braku zaangażowania lub niepewności.  
- Usunięcie punktu neutralnego może zmusić respondentów do zajęcia stanowiska, ale może też wprowadzać sztuczne odpowiedzi u osób rzeczywiście neutralnych.  
- Decyzja o użyciu punktu środkowego powinna być powiązana z celem pytania i charakterystyką badanej grupy.  
- W kontekście naszego projektu, gdzie ważna jest identyfikacja zarówno wyraźnych preferencji, jak i braku opinii, warto rozważyć testowanie obu wariantów w pilotażu.  

## 4. Komentarz krytyczny

W badaniach społeczności o zróżnicowanej aktywności i poziomie zaangażowania punkt neutralny może pełnić istotną funkcję diagnostyczną — pozwala odróżnić brak opinii od postaw skrajnych. Wersja ankiety powinna przewidywać analizę motywacji wyboru tego punktu, np. poprzez dodatkowe pytanie otwarte.

